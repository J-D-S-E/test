{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Código usando LLM no Hugging Face em Jupyter Notebook (Google Colab)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "z0R01eF-04vU",
                "outputId": "16080335-365a-4c7b-8478-62a4c5d3d7a4"
            },
            "outputs": [],
            "source": [
                "# Instala as bibliotecas necessárias\n",
                "!\tpip install transformers datasets accelerate huggingface_hub"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "o-xG-0p7-Vq8",
                "outputId": "8777c4e0-6f99-4c79-b877-e6015157e720"
            },
            "outputs": [],
            "source": [
                "# Importa as bibliotecas\n",
                "from transformers import pipeline\n",
                "from datasets import load_dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "p0eN0W8V-4J0",
                "outputId": "3f1749c3-1c51-47cf-89d2-966a747a712a"
            },
            "outputs": [],
            "source": [
                "# Carrega o modelo de linguagem pré-treinado (neste caso, GPT-2)\n",
                "generator = pipeline('text-generation', model='gpt2')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "qVqT-08r-4W6",
                "outputId": "35a32709-d491-480e-b777-3e8e353b237c"
            },
            "outputs": [],
            "source": [
                "# Define o texto de entrada\n",
                "text = 'O céu está azul e'\n",
                "\n",
                "# Gera texto usando o modelo\n",
                "output = generator(text, max_length=50, num_return_sequences=3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "vW9m1l4P-4zC",
                "outputId": "489490e0-04c8-478c-9150-e119b7b25c11"
            },
            "outputs": [],
            "source": [
                "# Imprime as saídas geradas\n",
                "for i, generated_text in enumerate(output):\n",
                "  print(f'Saída {i+1}: {generated_text['generated_text']}'\n",
                "  print('---')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Usando o modelo para gerar texto a partir de um dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "g1_q21_6-52H",
                "outputId": "b087e2e7-7694-4502-8d50-45b12d3d8c04"
            },
            "outputs": [],
            "source": [
                "# Carrega um dataset\n",
                "dataset = load_dataset('imdb')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "1J5gN86t-5o7",
                "outputId": "2b6b318c-3b39-4292-8527-342955a102c2"
            },
            "outputs": [],
            "source": [
                "# Itera sobre as primeiras 5 amostras do dataset\n",
                "for i in range(5):\n",
                "  text = dataset['train'][i]['text']\n",
                "  print(f'Texto de entrada: {text[:100]}...')\n",
                "  output = generator(text[:100], max_length=50, num_return_sequences=1)\n",
                "  print(f'Saída: {output[0]['generated_text']}'\n",
                "  print('---')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Salvando o modelo em seu próprio repositório Hugging Face"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "oJ30g4xL-5sM",
                "outputId": "b50e6c14-577c-4df7-ad26-01a319b639f2"
            },
            "outputs": [],
            "source": [
                "# Importe a biblioteca 'huggingface_hub'\n",
                "from huggingface_hub import notebook_login\n",
                "\n",
                "# Autentique-se com sua conta do Hugging Face\n",
                "notebook_login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "D39N-1z6-5vV",
                "outputId": "c7382c07-917d-432b-828f-a54566b3753f"
            },
            "outputs": [],
            "source": [
                "# Define o nome do repositório e o nome do modelo\n",
                "repo_name = 'meu-modelo-de-linguagem'\n",
                "model_name = 'meu-modelo'\n",
                "\n",
                "# Salva o modelo no repositório\n",
                "generator.save_pretrained(repo_name)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Carregando o modelo salvo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "1_J-1oS-5w9",
                "outputId": "4182583a-5910-458f-9c2f-2c646a0b225a"
            },
            "outputs": [],
            "source": [
                "# Carrega o modelo do repositório\n",
                "generator = pipeline('text-generation', model=f'your_huggingface_username/{repo_name}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "U0r722a8-5y2",
                "outputId": "9ab841c9-e545-4222-b801-1085f1287324"
            },
            "outputs": [],
            "source": [
                "# Testa o modelo carregado\n",
                "text = 'O céu está azul e'\n",
                "output = generator(text, max_length=50, num_return_sequences=3)\n",
                "for i, generated_text in enumerate(output):\n",
                "  print(f'Saída {i+1}: {generated_text['generated_text']}'\n",
                "  print('---')"
            ]
        }
    ]
}